# -*- coding: utf-8 -*-
"""langchain_groq.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hvp34ItRE0M5N5EJKK2zZ-9CH_4kp39y
"""

!pip install langchain-groq langchain-core python-dotenv

import os
os.environ["GROQ_API_KEY"] = "Add_your api key"

from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate

# 1. Initialize Groq LLM
llm = ChatGroq(
    model="llama-3.1-8b-instant",
    temperature=0.2
)

# 2. Create a prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant."),
    ("human", "{question}")
])

# 3. Build the chain
chain = prompt | llm

# 4. Run the chain
response = chain.invoke({"question": "Explain LangChain in simple words."})

print(response.content)

while True:
    user_input = input("You: ")
    if user_input == "exit":
        break

    response = chain.invoke({"question": user_input})
    print("Bot:", response.content)

import os
import gradio as gr
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate

# Set your key
os.environ["GROQ_API_KEY"] = "add your api "

# LangChain Groq model
llm = ChatGroq(
    model="llama-3.1-8b-instant",   # Updated to a currently supported model
    temperature=0.2
)

# Prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI assistant."),
    ("human", "{message}")
])

chain = prompt | llm

# Chat function for Gradio
def chat(message, history):
    print(f"Received message: {message}") # Debugging print
    try:
        response = chain.invoke({"message": message})
        bot_reply = response.content
        print(f"LLM response: {bot_reply}") # Debugging print
    except Exception as e:
        bot_reply = f"Error: {e}"
        print(f"Error during LLM invocation: {e}") # Debugging print
    return bot_reply

# Gradio Chat UI
with gr.Blocks(theme="soft") as demo:
    gr.Markdown("# ðŸ¤– AI Chatbot (Groq + LangChain)")
    gr.Markdown("Talk with a super-fast Groq model through a beautiful UI.")

    chatbot = gr.ChatInterface(
        fn=chat,
        chatbot=gr.Chatbot(
            height=400,
            show_label=False,
            placeholder="Type your message here...",
            type='messages'
        ),
        title="Groq x LangChain Chatbot",
        type='messages'
    )

demo.launch()



