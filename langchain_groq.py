# -*- coding: utf-8 -*-
"""langchain_groq.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hvp34ItRE0M5N5EJKK2zZ-9CH_4kp39y
"""

!pip install langchain-groq langchain-core python-dotenv

import os
os.environ["GROQ_API_KEY"] = "add_your_api_key"

from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate

# 1. Initialize Groq LLM
llm = ChatGroq(
    model="llama-3.1-8b-instant",
    temperature=0.2
)

# 2. Create a prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant."),
    ("human", "{question}")
])

# 3. Build the chain
chain = prompt | llm

# 4. Run the chain
response = chain.invoke({"question": "Explain LangChain in simple words."})

print(response.content)

while True:
    user_input = input("You: ")
    if user_input == "exit":
        break

    response = chain.invoke({"question": user_input})
    print("Bot:", response.content)





